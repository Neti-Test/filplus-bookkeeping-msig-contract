{
  "Version": "1.3",
  "ID": "f410fqpm3ely5mjpyifc33eqtuccxqq26azlso2liqza",
  "Issue Number": "395",
  "Client": {
    "Name": "Issue LM 3",
    "Region": "United States",
    "Industry": "IT & Technology Services",
    "Website": "https://pangeo-data.github.io/pangeo-cmip6-cloud/",
    "Social Media": "[at]pangeo_data (Twitter)",
    "Social Media Type": "Slack",
    "Role": "Data Preparer"
  },
  "Project": {
    "Brief history of your project and organization": "FrogHub has always defined itself as a tool developer and infrastructure builder in the Filecoin ecosystem. In 2019, we started to focus on technical solutions and development based on the IPFS protocol and Filecoin network. We have been working hard to become a qualified builder in the filecoin ecosystem..\n\nOur team is a very pure development team, more than 90% of which are developers, more than half of whom have more than 5 years of development experience in communication, Internet, blockchain and other industries. We hope that we can gain users' recognition by exporting useful tools and platforms.\n\nIn order to contribute to the filecoin community, we have developed the open source sector repair tool Filecoin-Sealer-Recover and the nft free authoring platform NFT-Creator.\nIn addition, we plan to provide a sector browser for the community in 2023 and build the liquidity pledge platform STFIL on FVM.\n\nSee the links below for details.\n\nmaking: https://github.com/orgs/froghub-io",
    "Is this project associated with other projects/ecosystem stakeholders?": "No",
    "Describe the data being stored onto Filecoin": "Zarr formatted data and Netcdf formatted data.\nThe sixth phase of global coupled ocean-atmosphere general circulation model ensemble.",
    "Where was the data currently stored in this dataset sourced from": "AWS Cloud",
    "How do you plan to prepare the dataset": "After we download data from the Internet, the data is cut into disks through Singularity, and then the hard disk is mailed to the SPs.",
    "Please share a sample of the data (a link to a file, an image, a table, etc., are good ways to do this.)": "aws s3 ls --no-sign-request s3://cmip6-pds/\naws s3 ls --no-sign-request s3://esgf-world/",
    "Confirm that this is a public dataset that can be retrieved by anyone on the network (i.e., no specific permissions or access rights are required to view the data)": "[X] I confirm",
    "What is the expected retrieval frequency for this data": "Yearly",
    "For how long do you plan to keep this dataset stored on Filecoin": "1.5 to 2 years",
    "In which geographies do you plan on making storage deals": "Greater China, Asia other than Greater China, North America, Europe",
    "How will you be distributing your data to storage providers": "Shipping hard drives",
    "Please list the provider IDs and location of the storage providers you will be working with. Note that it is a requirement to list a minimum of 5 unique provider IDs, and that your client address will be verified against this list in the future": "f03231154, HongKong\nf03218576, Portland, United States\nf03215853, Portland, United States\nf03157910, Shenzhen, China\nf03157905, Shenzhen, China\nf03220172, Singapore\nf03220176, HongKong\nf01025366, Qingdao, China",
    "Can you confirm that you will follow the Fil+ guideline (Data owner should engage at least 4 SPs and no single SP ID should receive >30% of a client's allocated DataCap)": "Yes"
  },
  "Datacap": {
    "Type": "ldn-v3",
    "Data Type": "Slingshot",
    "Total Requested Amount": "32 GiB",
    "Single Size Dataset": "5TiB",
    "Replicas": 8,
    "Weekly Allocation": "32 GiB"
  },
  "Lifecycle": {
    "State": "Submitted",
    "Validated At": "",
    "Validated By": "",
    "Active": true,
    "Updated At": "2025-09-04 08:11:31.774407114 UTC",
    "Active Request ID": "",
    "On Chain Address": "f410fqpm3ely5mjpyifc33eqtuccxqq26azlso2liqza",
    "Multisig Address": "false",
    "edited": false
  },
  "Allocation Requests": []
}